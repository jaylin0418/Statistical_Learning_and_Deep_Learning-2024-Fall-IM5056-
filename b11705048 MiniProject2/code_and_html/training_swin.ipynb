{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "此檔案進行包含 Dropout 的 Swin Transformer 訓練（針對全部資料集，無 Validation）。主要流程包括：\n",
        "\n",
        "1. **模型架構**：採用 Swin Transformer Base (224×224) 作為基底模型，並在最後的全連接層加入 Dropout（p=0.5）以防止 Overfitting。使用 `timm` 庫中的預訓練模型，並設置選項來凍結部分層（如 `layers.0` 和 `layers.1`）以提升訓練效率。\n",
        "\n",
        "2. **數據處理與增強**：\n",
        "   - 使用 `datasets.py` 中的 `MultiLabelDataset` 類別來處理標籤為多個類別的圖像數據。  \n",
        "   - 應用多種數據增強技術，如隨機裁剪、旋轉、色彩抖動等，來提高模型的泛化能力。  \n",
        "   - 使用 Mixup 技術，將不同樣本進行加權混合。\n",
        "\n",
        "3. **訓練配置**：\n",
        "   - 使用 `BCEWithLogitsLoss` 作為損失函數來處理多標籤問題，並配置 Adam Optimizer。  \n",
        "   - 設置學習率調度器（Cosine Annealing）來動態調整學習率。\n",
        "\n",
        "4. **評估指標**：訓練過程中計算 F1-score、Precision、Recall、MAP 等指標。\n",
        "\n",
        "5. **模型儲存與視覺化**：\n",
        "   - 每個訓練週期（Epoch）後保存模型參數，並記錄訓練損失與指標。  \n",
        "   - 使用 TensorBoard 來可視化訓練過程中的損失和指標變化，方便分析模型學習情況。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef9NizfZeNKQ",
        "outputId": "104a80ef-d5be-4b3d-a674-63c2b2ab637b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['swin_base_patch4_window7_224.ms_in1k', 'swin_base_patch4_window7_224.ms_in22k', 'swin_base_patch4_window7_224.ms_in22k_ft_in1k', 'swin_base_patch4_window12_384.ms_in1k', 'swin_base_patch4_window12_384.ms_in22k', 'swin_base_patch4_window12_384.ms_in22k_ft_in1k', 'swin_large_patch4_window7_224.ms_in22k', 'swin_large_patch4_window7_224.ms_in22k_ft_in1k', 'swin_large_patch4_window12_384.ms_in22k', 'swin_large_patch4_window12_384.ms_in22k_ft_in1k', 'swin_s3_base_224.ms_in1k', 'swin_s3_small_224.ms_in1k', 'swin_s3_tiny_224.ms_in1k', 'swin_small_patch4_window7_224.ms_in1k', 'swin_small_patch4_window7_224.ms_in22k', 'swin_small_patch4_window7_224.ms_in22k_ft_in1k', 'swin_tiny_patch4_window7_224.ms_in1k', 'swin_tiny_patch4_window7_224.ms_in22k', 'swin_tiny_patch4_window7_224.ms_in22k_ft_in1k', 'swinv2_base_window8_256.ms_in1k', 'swinv2_base_window12_192.ms_in22k', 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k', 'swinv2_base_window12to24_192to384.ms_in22k_ft_in1k', 'swinv2_base_window16_256.ms_in1k', 'swinv2_cr_small_224.sw_in1k', 'swinv2_cr_small_ns_224.sw_in1k', 'swinv2_cr_tiny_ns_224.sw_in1k', 'swinv2_large_window12_192.ms_in22k', 'swinv2_large_window12to16_192to256.ms_in22k_ft_in1k', 'swinv2_large_window12to24_192to384.ms_in22k_ft_in1k', 'swinv2_small_window8_256.ms_in1k', 'swinv2_small_window16_256.ms_in1k', 'swinv2_tiny_window8_256.ms_in1k', 'swinv2_tiny_window16_256.ms_in1k']\n"
          ]
        }
      ],
      "source": [
        "import timm\n",
        "print(timm.list_models('swin*', pretrained=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVkLflDR-zk1",
        "outputId": "6b7390b9-1ab8-414e-ac0a-614de7e951a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 37866\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:201: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:   0%|          | 0/592 [00:00<?, ?it/s]<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 1: 100%|██████████| 592/592 [11:00<00:00,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0898 | F1: 0.1092 | MAP: 0.0447\n",
            "Model for epoch 1 saved as model_epoch_1_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 2/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 2: 100%|██████████| 592/592 [10:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0698 | F1: 0.2314 | MAP: 0.1099\n",
            "Model for epoch 2 saved as model_epoch_2_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 3/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 3: 100%|██████████| 592/592 [10:24<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0647 | F1: 0.2686 | MAP: 0.1451\n",
            "Model for epoch 3 saved as model_epoch_3_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 4/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 4: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0616 | F1: 0.2955 | MAP: 0.1661\n",
            "Model for epoch 4 saved as model_epoch_4_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 5/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 5: 100%|██████████| 592/592 [10:28<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0597 | F1: 0.3149 | MAP: 0.1816\n",
            "Model for epoch 5 saved as model_epoch_5_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 6/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 6: 100%|██████████| 592/592 [10:27<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0590 | F1: 0.3128 | MAP: 0.1841\n",
            "Model for epoch 6 saved as model_epoch_6_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 7/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 7: 100%|██████████| 592/592 [10:34<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0580 | F1: 0.3279 | MAP: 0.1992\n",
            "Model for epoch 7 saved as model_epoch_7_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 8/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 8: 100%|██████████| 592/592 [10:31<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0576 | F1: 0.3374 | MAP: 0.2125\n",
            "Model for epoch 8 saved as model_epoch_8_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 9/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 9: 100%|██████████| 592/592 [10:48<00:00,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0568 | F1: 0.3396 | MAP: 0.2175\n",
            "Model for epoch 9 saved as model_epoch_9_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 10/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 10: 100%|██████████| 592/592 [10:33<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0565 | F1: 0.3191 | MAP: 0.1964\n",
            "Model for epoch 10 saved as model_epoch_10_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 11/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 11:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 11: 100%|██████████| 592/592 [10:22<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0569 | F1: 0.3241 | MAP: 0.2072\n",
            "Model for epoch 11 saved as model_epoch_11_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 12/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 12:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 12: 100%|██████████| 592/592 [10:26<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0559 | F1: 0.3411 | MAP: 0.2213\n",
            "Model for epoch 12 saved as model_epoch_12_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 13/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 13:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 13: 100%|██████████| 592/592 [10:22<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0540 | F1: 0.3470 | MAP: 0.2154\n",
            "Model for epoch 13 saved as model_epoch_13_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 14/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 14:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 14: 100%|██████████| 592/592 [10:25<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0538 | F1: 0.3396 | MAP: 0.2168\n",
            "Model for epoch 14 saved as model_epoch_14_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 15/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 15:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 15: 100%|██████████| 592/592 [10:28<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0538 | F1: 0.3555 | MAP: 0.2355\n",
            "Model for epoch 15 saved as model_epoch_15_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 16/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 16:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 16: 100%|██████████| 592/592 [10:27<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0529 | F1: 0.3478 | MAP: 0.2202\n",
            "Model for epoch 16 saved as model_epoch_16_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 17/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 17:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 17: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0528 | F1: 0.3675 | MAP: 0.2473\n",
            "Model for epoch 17 saved as model_epoch_17_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 18/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 18:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 18: 100%|██████████| 592/592 [10:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0524 | F1: 0.3728 | MAP: 0.2609\n",
            "Model for epoch 18 saved as model_epoch_18_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 19/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 19:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 19: 100%|██████████| 592/592 [10:25<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0515 | F1: 0.3804 | MAP: 0.2622\n",
            "Model for epoch 19 saved as model_epoch_19_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 20/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 20:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 20: 100%|██████████| 592/592 [10:26<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0505 | F1: 0.3827 | MAP: 0.2608\n",
            "Model for epoch 20 saved as model_epoch_20_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 21/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 21:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 21: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0497 | F1: 0.3945 | MAP: 0.2714\n",
            "Model for epoch 21 saved as model_epoch_21_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 22/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 22:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 22: 100%|██████████| 592/592 [10:18<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0492 | F1: 0.3884 | MAP: 0.2653\n",
            "Model for epoch 22 saved as model_epoch_22_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 23/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 23:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 23: 100%|██████████| 592/592 [10:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0488 | F1: 0.3973 | MAP: 0.2764\n",
            "Model for epoch 23 saved as model_epoch_23_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 24/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 24:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 24: 100%|██████████| 592/592 [10:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0472 | F1: 0.4049 | MAP: 0.2839\n",
            "Model for epoch 24 saved as model_epoch_24_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 25/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 25:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 25: 100%|██████████| 592/592 [10:21<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0471 | F1: 0.3923 | MAP: 0.2773\n",
            "Model for epoch 25 saved as model_epoch_25_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 26/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 26:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 26: 100%|██████████| 592/592 [10:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0462 | F1: 0.4228 | MAP: 0.3075\n",
            "Model for epoch 26 saved as model_epoch_26_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 27/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 27:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 27: 100%|██████████| 592/592 [10:16<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0452 | F1: 0.4233 | MAP: 0.3054\n",
            "Model for epoch 27 saved as model_epoch_27_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 28/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 28:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 28: 100%|██████████| 592/592 [10:13<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0456 | F1: 0.4180 | MAP: 0.3064\n",
            "Model for epoch 28 saved as model_epoch_28_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 29/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 29:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 29: 100%|██████████| 592/592 [10:11<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0450 | F1: 0.4080 | MAP: 0.3049\n",
            "Model for epoch 29 saved as model_epoch_29_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 30/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 30:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 30: 100%|██████████| 592/592 [10:14<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0425 | F1: 0.4268 | MAP: 0.3129\n",
            "Model for epoch 30 saved as model_epoch_30_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 31/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 31:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 31: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0427 | F1: 0.4342 | MAP: 0.3256\n",
            "Model for epoch 31 saved as model_epoch_31_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 32/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 32:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 32: 100%|██████████| 592/592 [10:11<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0423 | F1: 0.4228 | MAP: 0.3071\n",
            "Model for epoch 32 saved as model_epoch_32_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 33/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 33:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 33: 100%|██████████| 592/592 [10:18<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0409 | F1: 0.4448 | MAP: 0.3276\n",
            "Model for epoch 33 saved as model_epoch_33_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 34/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 34:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 34: 100%|██████████| 592/592 [10:11<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0412 | F1: 0.4564 | MAP: 0.3671\n",
            "Model for epoch 34 saved as model_epoch_34_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 35/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 35:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 35: 100%|██████████| 592/592 [10:08<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0399 | F1: 0.4693 | MAP: 0.3646\n",
            "Model for epoch 35 saved as model_epoch_35_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 36/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 36:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 36: 100%|██████████| 592/592 [10:12<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0395 | F1: 0.4724 | MAP: 0.3759\n",
            "Model for epoch 36 saved as model_epoch_36_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 37/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 37:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 37: 100%|██████████| 592/592 [10:13<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0387 | F1: 0.4500 | MAP: 0.3409\n",
            "Model for epoch 37 saved as model_epoch_37_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 38/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 38:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 38: 100%|██████████| 592/592 [10:15<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0378 | F1: 0.4746 | MAP: 0.3774\n",
            "Model for epoch 38 saved as model_epoch_38_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 39/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 39:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 39: 100%|██████████| 592/592 [10:16<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0375 | F1: 0.4963 | MAP: 0.3936\n",
            "Model for epoch 39 saved as model_epoch_39_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 40/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 40:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 40: 100%|██████████| 592/592 [10:10<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0368 | F1: 0.4793 | MAP: 0.3848\n",
            "Model for epoch 40 saved as model_epoch_40_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 41/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 41:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 41: 100%|██████████| 592/592 [10:09<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0368 | F1: 0.4809 | MAP: 0.3950\n",
            "Model for epoch 41 saved as model_epoch_41_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 42/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 42:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 42: 100%|██████████| 592/592 [10:11<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0366 | F1: 0.4926 | MAP: 0.4009\n",
            "Model for epoch 42 saved as model_epoch_42_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 43/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 43:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 43: 100%|██████████| 592/592 [10:14<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0361 | F1: 0.5047 | MAP: 0.4180\n",
            "Model for epoch 43 saved as model_epoch_43_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 44/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 44:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 44: 100%|██████████| 592/592 [10:16<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0357 | F1: 0.5034 | MAP: 0.4245\n",
            "Model for epoch 44 saved as model_epoch_44_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 45/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 45:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 45: 100%|██████████| 592/592 [10:14<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0351 | F1: 0.4953 | MAP: 0.4082\n",
            "Model for epoch 45 saved as model_epoch_45_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 46/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 46:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 46: 100%|██████████| 592/592 [10:22<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0355 | F1: 0.5105 | MAP: 0.4225\n",
            "Model for epoch 46 saved as model_epoch_46_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 47/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 47:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 47: 100%|██████████| 592/592 [10:26<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0344 | F1: 0.4835 | MAP: 0.3842\n",
            "Model for epoch 47 saved as model_epoch_47_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 48/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 48:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 48: 100%|██████████| 592/592 [10:23<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0344 | F1: 0.4705 | MAP: 0.3711\n",
            "Model for epoch 48 saved as model_epoch_48_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 49/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 49:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 49: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0337 | F1: 0.4880 | MAP: 0.3984\n",
            "Model for epoch 49 saved as model_epoch_49_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 50/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 50:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 50: 100%|██████████| 592/592 [10:21<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0345 | F1: 0.5011 | MAP: 0.4278\n",
            "Model for epoch 50 saved as model_epoch_50_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 51/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 51:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 51: 100%|██████████| 592/592 [10:18<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0337 | F1: 0.4716 | MAP: 0.3700\n",
            "Model for epoch 51 saved as model_epoch_51_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 52/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 52:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 52: 100%|██████████| 592/592 [10:18<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0342 | F1: 0.5119 | MAP: 0.4215\n",
            "Model for epoch 52 saved as model_epoch_52_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 53/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 53:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 53: 100%|██████████| 592/592 [10:26<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0344 | F1: 0.4918 | MAP: 0.3938\n",
            "Model for epoch 53 saved as model_epoch_53_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 54/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 54:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 54: 100%|██████████| 592/592 [10:30<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0339 | F1: 0.4944 | MAP: 0.4047\n",
            "Model for epoch 54 saved as model_epoch_54_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 55/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 55:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 55: 100%|██████████| 592/592 [10:23<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0350 | F1: 0.5033 | MAP: 0.4236\n",
            "Model for epoch 55 saved as model_epoch_55_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 56/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 56:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 56: 100%|██████████| 592/592 [10:25<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0339 | F1: 0.4989 | MAP: 0.4152\n",
            "Model for epoch 56 saved as model_epoch_56_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 57/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 57:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 57: 100%|██████████| 592/592 [10:21<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0339 | F1: 0.4781 | MAP: 0.3838\n",
            "Model for epoch 57 saved as model_epoch_57_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 58/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 58:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 58: 100%|██████████| 592/592 [10:26<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0345 | F1: 0.4851 | MAP: 0.3913\n",
            "Model for epoch 58 saved as model_epoch_58_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 59/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 59:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 59: 100%|██████████| 592/592 [10:20<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0345 | F1: 0.4946 | MAP: 0.3899\n",
            "Model for epoch 59 saved as model_epoch_59_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 60/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 60:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 60: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0341 | F1: 0.4857 | MAP: 0.3939\n",
            "Model for epoch 60 saved as model_epoch_60_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 61/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 61:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 61: 100%|██████████| 592/592 [10:21<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0351 | F1: 0.5012 | MAP: 0.4142\n",
            "Model for epoch 61 saved as model_epoch_61_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 62/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 62:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 62: 100%|██████████| 592/592 [10:21<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0356 | F1: 0.4934 | MAP: 0.3943\n",
            "Model for epoch 62 saved as model_epoch_62_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 63/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 63:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 63: 100%|██████████| 592/592 [10:33<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0357 | F1: 0.4836 | MAP: 0.3896\n",
            "Model for epoch 63 saved as model_epoch_63_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 64/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 64:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 64: 100%|██████████| 592/592 [10:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0368 | F1: 0.4777 | MAP: 0.3817\n",
            "Model for epoch 64 saved as model_epoch_64_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 65/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 65:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 65: 100%|██████████| 592/592 [10:24<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0362 | F1: 0.5089 | MAP: 0.4282\n",
            "Model for epoch 65 saved as model_epoch_65_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 66/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 66:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 66: 100%|██████████| 592/592 [10:33<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0375 | F1: 0.4867 | MAP: 0.3896\n",
            "Model for epoch 66 saved as model_epoch_66_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 67/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 67:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 67: 100%|██████████| 592/592 [10:20<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0376 | F1: 0.4653 | MAP: 0.3562\n",
            "Model for epoch 67 saved as model_epoch_67_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 68/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 68:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 68: 100%|██████████| 592/592 [10:26<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0385 | F1: 0.4420 | MAP: 0.3428\n",
            "Model for epoch 68 saved as model_epoch_68_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 69/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 69:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 69: 100%|██████████| 592/592 [10:18<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0384 | F1: 0.4567 | MAP: 0.3597\n",
            "Model for epoch 69 saved as model_epoch_69_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 70/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 70:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 70: 100%|██████████| 592/592 [10:14<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0387 | F1: 0.4689 | MAP: 0.3653\n",
            "Model for epoch 70 saved as model_epoch_70_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 71/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 71:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 71: 100%|██████████| 592/592 [10:29<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0391 | F1: 0.4489 | MAP: 0.3480\n",
            "Model for epoch 71 saved as model_epoch_71_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 72/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 72:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 72: 100%|██████████| 592/592 [10:14<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0397 | F1: 0.4341 | MAP: 0.3299\n",
            "Model for epoch 72 saved as model_epoch_72_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 73/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 73:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 73: 100%|██████████| 592/592 [10:19<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0406 | F1: 0.4428 | MAP: 0.3371\n",
            "Model for epoch 73 saved as model_epoch_73_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 74/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 74:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 74: 100%|██████████| 592/592 [10:20<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0411 | F1: 0.4389 | MAP: 0.3329\n",
            "Model for epoch 74 saved as model_epoch_74_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 75/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 75:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 75: 100%|██████████| 592/592 [10:18<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0418 | F1: 0.4519 | MAP: 0.3475\n",
            "Model for epoch 75 saved as model_epoch_75_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 76/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 76:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 76: 100%|██████████| 592/592 [10:25<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0422 | F1: 0.4159 | MAP: 0.3010\n",
            "Model for epoch 76 saved as model_epoch_76_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 77/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 77:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 77: 100%|██████████| 592/592 [10:22<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0429 | F1: 0.4302 | MAP: 0.3280\n",
            "Model for epoch 77 saved as model_epoch_77_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 78/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 78:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 78: 100%|██████████| 592/592 [10:20<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0426 | F1: 0.4558 | MAP: 0.3565\n",
            "Model for epoch 78 saved as model_epoch_78_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 79/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 79:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 79: 100%|██████████| 592/592 [10:22<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0434 | F1: 0.4353 | MAP: 0.3207\n",
            "Model for epoch 79 saved as model_epoch_79_swin_no_freeze.pth.\n",
            "\n",
            "Epoch 80/80\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 80:   0%|          | 0/592 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-4b9f567871ef>:224: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Training Epoch 80: 100%|██████████| 592/592 [10:22<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0437 | F1: 0.4268 | MAP: 0.3157\n",
            "Model for epoch 80 saved as model_epoch_80_swin_no_freeze.pth.\n",
            "Final model saved as 'final_model_swin_transformer_no_freeze.pth'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from timm import create_model\n",
        "\n",
        "from datasets import MultiLabelDataset\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiLabelSwinTransformer(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, freeze_layers=False):\n",
        "        super(MultiLabelSwinTransformer, self).__init__()\n",
        "        # 使用 Swin Base (224×224)\n",
        "        self.model = create_model(\n",
        "            'swin_base_patch4_window7_224',\n",
        "            pretrained=pretrained\n",
        "        )\n",
        "        in_features = self.model.head.in_features\n",
        "        self.model.head = nn.Identity()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "        if freeze_layers:\n",
        "            for name, param in self.model.named_parameters():\n",
        "                if \"layers.0\" in name or \"layers.1\" in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, 3, 224, 224]\n",
        "\n",
        "        x = self.model.forward_features(x)\n",
        "        # 此時 x shape: [batch_size, 7, 7, 1024]\n",
        "\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        # 現在 x shape: [batch_size, 1024, 7, 7]\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        # shape: [batch_size, 1024, 1, 1]\n",
        "\n",
        "        x = x.flatten(1)\n",
        "        # shape: [batch_size, 1024]\n",
        "\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_scores):\n",
        "\n",
        "    from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['f1'] = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    metrics['precision'] = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    metrics['recall'] = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "\n",
        "    try:\n",
        "        metrics['roc_auc'] = roc_auc_score(y_true, y_pred, average='micro')\n",
        "    except:\n",
        "        metrics['roc_auc'] = 0.0\n",
        "\n",
        "    try:\n",
        "        ap_per_class = average_precision_score(y_true, y_scores, average=None)\n",
        "        metrics['map'] = np.mean(ap_per_class)\n",
        "    except Exception as e:\n",
        "        print(\"Error calculating MAP:\", e)\n",
        "        metrics['map'] = 0.0\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    \"\"\"\n",
        "    x: [batch_size, C, H, W]\n",
        "    y: [batch_size, num_classes]\n",
        "    alpha: default=1.0\n",
        "    Returns:\n",
        "        mixed_x, y_a, y_b, lam\n",
        "    \"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.0\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    if torch.cuda.is_available():\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"\n",
        "    pred: [batch_size, num_classes] (logits)\n",
        "    y_a, y_b: [batch_size, num_classes]\n",
        "    lam: mixup ratio\n",
        "    \"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    with open('class_mapping.json', 'r', encoding='utf-8') as f:\n",
        "        class_mapping = json.load(f)\n",
        "    num_classes = len(class_mapping)\n",
        "\n",
        "    ground_truth = pd.read_csv('ground_truth_probabilities.csv')\n",
        "    if 'filename' not in ground_truth.columns:\n",
        "        raise ValueError(\"CSV 文件缺少 'filename' 欄位，請檢查。\")\n",
        "\n",
        "    print(f\"Number of training samples: {len(ground_truth)}\")\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    img_dir = 'train_data'\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        dataframe=ground_truth,\n",
        "        img_dir=img_dir,\n",
        "        class_mapping=class_mapping,\n",
        "        transform=train_transforms\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # freeze_layers=False\n",
        "    model = MultiLabelSwinTransformer(\n",
        "        num_classes=num_classes,\n",
        "        pretrained=True,\n",
        "        freeze_layers=False\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    writer = SummaryWriter('runs/multi_label_experiment_swin_no_freeze')\n",
        "\n",
        "    num_epochs = 80\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixup\n",
        "            inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=1.0)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)  # shape [batch_size, num_classes]\n",
        "                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs).detach().cpu().numpy()  # (batch_size, num_classes)\n",
        "            all_preds.append(preds)\n",
        "            all_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        all_preds = np.vstack(all_preds)   # shape (N, num_classes)\n",
        "        all_labels = np.vstack(all_labels) # shape (N, num_classes)\n",
        "\n",
        "        preds_binary = (all_preds > 0.5).astype(int)\n",
        "        train_metrics = calculate_metrics(all_labels, preds_binary, all_preds)\n",
        "\n",
        "        print(\n",
        "            f\"Training Loss: {epoch_loss:.4f} | \"\n",
        "            f\"F1: {train_metrics['f1']:.4f} | \"\n",
        "            f\"MAP: {train_metrics['map']:.4f}\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"model_epoch_{epoch+1}_swin_no_freeze.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"Model for epoch {epoch+1} saved as {model_path}.\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
        "        writer.add_scalar('F1/train', train_metrics['f1'], epoch)\n",
        "        writer.add_scalar('mAP/train', train_metrics['map'], epoch)\n",
        "\n",
        "    torch.save(model.state_dict(), 'final_model_swin_transformer_no_freeze.pth')\n",
        "    print(\"Final model saved as 'final_model_swin_transformer_no_freeze.pth'.\")\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
